# Script de MigraciÃ³n del Blog Furgocasa

Este script automatiza la extracciÃ³n de todos los artÃ­culos del blog antiguo de Furgocasa (https://www.furgocasa.com/es/blog) y genera archivos para importarlos en la nueva base de datos.

## ğŸ“‹ CaracterÃ­sticas

El script extrae automÃ¡ticamente:
- âœ… **TÃ­tulo** del artÃ­culo
- âœ… **URL completa** y **slug** (Ãºltima parte de la URL)
- âœ… **CategorÃ­a** (rutas, noticias, vehÃ­culos)
- âœ… **Contenido HTML** completo del artÃ­culo
- âœ… **Imagen destacada** (og:image o primera imagen)
- âœ… **Extracto/Excerpt** (meta description)
- âœ… **Fecha de publicaciÃ³n**
- âœ… **Meta tags** (title, description, keywords)
- âœ… **Tiempo de lectura** estimado

## ğŸš€ Uso

### Paso 1: Ejecutar el scraper

```bash
npm run scrape:blog
```

Este comando procesarÃ¡ todas las categorÃ­as del blog y extraerÃ¡ todos los artÃ­culos encontrados.

### Paso 2: Archivos generados

El script genera automÃ¡ticamente 3 archivos en la carpeta `scripts/`:

1. **`blog-articles.json`** - Datos completos en formato JSON
2. **`import-blog-articles.sql`** - Script SQL listo para ejecutar en Supabase
3. **`blog-articles-summary.csv`** - Resumen en formato CSV para revisiÃ³n

## ğŸ“‚ Estructura de URLs

El script respeta la estructura de URLs del blog antiguo:

```
https://www.furgocasa.com/es/blog/rutas/nombre-del-articulo
https://www.furgocasa.com/es/blog/noticias/nombre-del-articulo
https://www.furgocasa.com/es/blog/vehiculos/nombre-del-articulo
```

Y las mapea correctamente a las categorÃ­as de la nueva base de datos:
- `rutas` â†’ content_categories.slug = 'rutas'
- `noticias` â†’ content_categories.slug = 'noticias'
- `vehiculos` â†’ content_categories.slug = 'vehiculos'

## ğŸ’¾ Importar a Supabase

Una vez generado el archivo SQL, puedes importarlo de dos formas:

### OpciÃ³n 1: Desde el dashboard de Supabase
1. Abre el dashboard de Supabase
2. Ve a la secciÃ³n SQL Editor
3. Copia y pega el contenido de `import-blog-articles.sql`
4. Ejecuta el script

### OpciÃ³n 2: Desde la lÃ­nea de comandos
```bash
# Conectar a tu base de datos
psql -h [tu-host] -U postgres -d postgres

# Ejecutar el script
\i scripts/import-blog-articles.sql
```

## ğŸ” VerificaciÃ³n

El script SQL incluye queries de verificaciÃ³n al final que mostrarÃ¡n:
- Lista de todos los artÃ­culos importados con su categorÃ­a
- Resumen del total de artÃ­culos por categorÃ­a

## âš™ï¸ ConfiguraciÃ³n Avanzada

Si necesitas modificar el comportamiento del script, puedes editar `scripts/scrape-blog.js`:

### Cambiar categorÃ­as a procesar
```javascript
const BLOG_CATEGORIES = [
  { slug: 'rutas', url: 'https://www.furgocasa.com/es/blog/rutas' },
  { slug: 'noticias', url: 'https://www.furgocasa.com/es/blog/noticias' },
  { slug: 'vehiculos', url: 'https://www.furgocasa.com/es/blog/vehiculos' }
];
```

### Ajustar selectores CSS
Si la estructura HTML del blog cambia, puedes modificar los selectores:
```javascript
const contentSelectors = [
  'article',
  '.blog-content',
  '.post-content',
  // AÃ±ade mÃ¡s selectores aquÃ­
];
```

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error: "Cannot find module 'puppeteer'"
```bash
npm install puppeteer --save-dev --legacy-peer-deps
```

### Error de timeout
Si algunos artÃ­culos tardan mucho en cargar, aumenta el timeout en `scrape-blog.js`:
```javascript
await page.goto(url, { 
  waitUntil: 'networkidle2',
  timeout: 120000  // 2 minutos
});
```

### El script no encuentra artÃ­culos
1. Verifica que las URLs de las categorÃ­as sean correctas
2. Inspecciona la estructura HTML del blog para ajustar los selectores
3. AsegÃºrate de tener conexiÃ³n a internet estable

## ğŸ“Š Ejemplo de Salida

```
ğŸš€ Iniciando extracciÃ³n del blog de Furgocasa...

ğŸ“‚ Procesando categorÃ­a: rutas
   URL: https://www.furgocasa.com/es/blog/rutas
   âœ… Encontrados 25 artÃ­culos
   ğŸ“„ [1/25] Extrayendo: https://www.furgocasa.com/es/blog/rutas/los-10-mejores-planes-para-septiembre...
      âœ… Los 10 mejores planes para Septiembre con tu camper de alquiler
   ...

ğŸ“‚ Procesando categorÃ­a: noticias
   ...

âœ… ExtracciÃ³n completada: 75 artÃ­culos encontrados

ğŸ’¾ Datos guardados en: scripts/blog-articles.json
ğŸ“ Archivo SQL generado: scripts/import-blog-articles.sql
ğŸ“Š Resumen CSV generado: scripts/blog-articles-summary.csv
```

## ğŸ“ Notas Importantes

- El script respeta los slugs originales de las URLs para mantener el SEO
- Las imÃ¡genes se mantienen como URLs externas por ahora
- Los tres primeros artÃ­culos se marcan automÃ¡ticamente como "destacados"
- Todo el contenido se importa con estado `published`
- Los artÃ­culos duplicados se actualizan en lugar de crear duplicados (usando `ON CONFLICT`)

## ğŸ”„ ActualizaciÃ³n del Blog

Si necesitas actualizar el contenido del blog en el futuro, simplemente:
1. Ejecuta nuevamente `npm run scrape:blog`
2. El script regenerarÃ¡ los archivos con el contenido mÃ¡s reciente
3. Ejecuta el SQL nuevamente (actualizarÃ¡ los artÃ­culos existentes)

## ğŸ’¡ Siguientes Pasos

DespuÃ©s de importar los artÃ­culos:
1. Revisa que las imÃ¡genes se vean correctamente
2. Verifica los meta tags para SEO
3. Considera descargar las imÃ¡genes y subirlas a tu propio storage
4. Ajusta los artÃ­culos destacados si es necesario
5. Configura las rutas en Next.js para servir los artÃ­culos

---

**Desarrollado para Furgocasa** - Sistema de migraciÃ³n del blog
